
    #model, loss, opt = SequentialClassification(x_normalised_train, y_train)


    #history = model.fit(x_normalised_train, y_train, validation_data=(x_normalised_test, y_test), epochs=num_epoch, batch_size=num_batch)


'''
        dataframes = []
        for file_name in training_files:
            df = pd.read_csv(data_directory + file_name)
            dataframes.append(df)
        data = pd.concat(dataframes)

        x = data[['Mean_Speed', 'Estimated_Travel_Time', 'Traffic_Level', 'Total_Neighbours', 'Length']]
        for col in x:
            data[col] = data[col].astype(float)
        y = data[['Rank']]
        #y = one_hot_encode(y)

        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)

        x_train_mean = np.mean(x_train)
        x_train_std = np.std(x_train)
        x_normalised_train = 0.5 * (np.tanh(0.01 * ((x_train - x_train_mean) / x_train_std)) + 1)

        x_test_mean = np.mean(x_test)
        x_test_std = np.std(x_test)
        x_normalised_test = 0.5 * (np.tanh(0.01 * ((x_test - x_test_mean) / x_test_std)) + 1)'''



def SequentialClassification(x_train, y_train):
    model = Sequential()
    model.add(Dense(64, activation='swish', kernel_initializer='he_normal', input_shape=(x_train.shape[1],)))
    model.add(Dense(32, activation='swish', kernel_initializer='he_normal'))
    model.add(Dense(20, activation='swish', kernel_initializer='he_normal'))
    model.add(Dense(15, activation='sigmoid'))

    opt = tf.keras.optimizers.Adam(learning_rate=0.005)
    #opt = SGD(lr=0.01, momentum=0.9)

    #loss_method = "binary_crossentropy"
    #loss_method = "squared_hinge"
    loss_method = "mean_squared_error"
    #loss_method = "mean_absolute_error"
    model.compile(loss=loss_method , optimizer=opt, metrics=["accuracy"])

    return [model, loss_method, opt]


